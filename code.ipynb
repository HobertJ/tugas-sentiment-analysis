{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05321393",
   "metadata": {},
   "source": [
    "# PR Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbe30a3",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f2d3276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Sastrawi in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing dependencies of pyodbc: Invalid version: '4.0.0-unsupported'\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 483, in run\n",
      "    installed_versions[distribution.canonical_name] = distribution.version\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\", line 192, in version\n",
      "    return parse_version(self._dist.version)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 202, in __init__\n",
      "    raise InvalidVersion(f\"Invalid version: '{version}'\")\n",
      "pip._vendor.packaging.version.InvalidVersion: Invalid version: '4.0.0-unsupported'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stanza in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.9.2)\n",
      "Requirement already satisfied: emoji in c:\\users\\asus\\anaconda3\\lib\\site-packages (from stanza) (2.13.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing dependencies of pyodbc: Invalid version: '4.0.0-unsupported'\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 483, in run\n",
      "    installed_versions[distribution.canonical_name] = distribution.version\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\", line 192, in version\n",
      "    return parse_version(self._dist.version)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 202, in __init__\n",
      "    raise InvalidVersion(f\"Invalid version: '{version}'\")\n",
      "pip._vendor.packaging.version.InvalidVersion: Invalid version: '4.0.0-unsupported'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from stanza) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.15.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from stanza) (5.27.3)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (from stanza) (2.26.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\anaconda3\\lib\\site-packages (from stanza) (2.6.3)\n",
      "Requirement already satisfied: torch>=1.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from stanza) (2.0.1+cu117)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\anaconda3\\lib\\site-packages (from stanza) (4.62.3)\n",
      "Requirement already satisfied: tomli in c:\\users\\asus\\anaconda3\\lib\\site-packages (from stanza) (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (3.3.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (1.9)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (2.11.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->stanza) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->stanza) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->stanza) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->stanza) (3.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tqdm->stanza) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.3.0->stanza) (1.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from sympy->torch>=1.3.0->stanza) (1.2.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\asus\\anaconda3\\lib\\site-packages (4.44.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing dependencies of pyodbc: Invalid version: '4.0.0-unsupported'\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 483, in run\n",
      "    installed_versions[distribution.canonical_name] = distribution.version\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\", line 192, in version\n",
      "    return parse_version(self._dist.version)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 202, in __init__\n",
      "    raise InvalidVersion(f\"Invalid version: '{version}'\")\n",
      "pip._vendor.packaging.version.InvalidVersion: Invalid version: '4.0.0-unsupported'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->transformers) (3.2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# library for stopwords, stemmer\n",
    "!pip install Sastrawi\n",
    "\n",
    "# library for entity masking\n",
    "!pip install stanza\n",
    "\n",
    "# library for entity masking\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d9840d",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1fec684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence sentiment\n",
       "0  warung ini dimiliki oleh pengusaha pabrik tahu...  positive\n",
       "1  mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n",
       "2  lokasi strategis di jalan sumatera bandung . t...  positive\n",
       "3  betapa bahagia nya diri ini saat unboxing pake...  positive\n",
       "4  duh . jadi mahasiswa jangan sombong dong . kas...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"data/train_preprocess.tsv\", sep='\\t', names=['sentence', 'sentiment'])\n",
    "test_data = pd.read_csv(\"data/test_preprocess.tsv\", sep='\\t', names=['sentence', 'sentiment'])\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fabd990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran data train: (11000, 2)\n",
      "Ukuran data test:, (500, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ukuran data train:\", train_data.shape)\n",
    "print(f\"Ukuran data test:,\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c65cbc",
   "metadata": {},
   "source": [
    "## Preprocessing (train and test data)\n",
    "\n",
    "Preprocessing yang dilakukan adalah :\n",
    "1. Removing character other than alphabet\n",
    "2. Lowercase\n",
    "3. Dropping Stopwords\n",
    "4. Stemming\n",
    "5. Entity Masking (belum sempat diimplement karena library yang dipakai bermasalah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eaa177b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "# import stanza\n",
    "# stanza.download('id')\n",
    "from transformers import pipeline\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \n",
    "    # function for entity masking\n",
    "    \n",
    "    def entity_masking(text):\n",
    "        masked_text = text\n",
    "#         doc = nlp(text)\n",
    "        ner_results = ner(text)\n",
    "        for entity in ner_results:\n",
    "            entity_type = entity.type\n",
    "            entity_text = entity.text\n",
    "\n",
    "            # Replace the entity with a mask based on its type\n",
    "            if entity_type == 'PERSON':\n",
    "                masked_text = masked_text.replace(entity_text, '[PERSON]')\n",
    "            elif entity_type == 'ORG':\n",
    "                masked_text = masked_text.replace(entity_text, '[ORG]')\n",
    "            elif entity_type == 'LOC':\n",
    "                masked_text = masked_text.replace(entity_text, '[LOC]')\n",
    "        return masked_text\n",
    "    \n",
    "    # create a stemmer\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "\n",
    "    # create a stopwords remover\n",
    "    stop_factory = StopWordRemoverFactory()\n",
    "\n",
    "    # additional stopwords\n",
    "    more_stopword = []\n",
    "\n",
    "    # stopwords from the factory and additional stopwords combined\n",
    "    stopwords = stop_factory.get_stop_words() + more_stopword\n",
    "    \n",
    "    corpus = []\n",
    "\n",
    "    for i in range(0, len(data)):\n",
    "\n",
    "        # removing any character other than alphabet\n",
    "        sentence = re.sub('[^a-zA-Z]', ' ', data['sentence'][i])\n",
    "\n",
    "        # lowercase the sentence\n",
    "        sentence = sentence.lower()\n",
    "        \n",
    "        # remove stopwords\n",
    "        sentence = sentence.split()\n",
    "        sentence = [word for word in sentence if word not in stopwords]\n",
    "        sentence = ' '.join(sentence)\n",
    "\n",
    "        # entity masking\n",
    "#         masked_text = entity_masking(sentence)\n",
    "\n",
    "        # stem the word \n",
    "        stemmed_text = stemmer.stem(sentence)\n",
    "\n",
    "        # add the stemmed sentence to corpus\n",
    "        corpus.append(stemmed_text)\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82a35bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_data = preprocess_data(train_data)\n",
    "preprocessed_test_data = preprocess_data(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c485a17b",
   "metadata": {},
   "source": [
    "## Raw vs Preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65ded0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL:\n",
      "warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung . tahu berkualitas , dipadu keahlian memasak , dipadu kretivitas , jadilah warung yang menyajikan menu utama berbahan tahu , ditambah menu umum lain seperti ayam . semuanya selera indonesia . harga cukup terjangkau . jangan lewatkan tahu bletoka nya , tidak kalah dengan yang asli dari tegal !\n",
      "\n",
      "PREPROCESSED:\n",
      "warung milik usaha pabrik tahu puluh tahun kenal buat tahu putih bandung tahu kualitas padu ahli masak padu kretivitas jadi warung saji menu utama bahan tahu tambah menu umum ayam semua selera indonesia harga cukup jangkau jangan lewat tahu bletoka nya kalah asli tegal\n"
     ]
    }
   ],
   "source": [
    "# original sentence\n",
    "print(\"ORIGINAL:\")\n",
    "print(train_data['sentence'][0])\n",
    "\n",
    "print()\n",
    "\n",
    "# preprocessed sentence\n",
    "print(\"PREPROCESSED:\")\n",
    "print(preprocessed_train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81bd0be",
   "metadata": {},
   "source": [
    "## Training and Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6037cc",
   "metadata": {},
   "source": [
    "### Variation of Feature with Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d48afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words with boolean as word feature value\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=500, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9166882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words with TF as word feature value\n",
    "cv_tf = CountVectorizer(max_features=500, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e584713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words with TF-IDF as word feature value\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv_tfidf = TfidfVectorizer(max_features=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e5b5b4",
   "metadata": {},
   "source": [
    "### Feature (X) and Label Data (y) with each Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c53e7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label is the same for all variation\n",
    "y_train = train_data.iloc[:, -1].values\n",
    "y_test = test_data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69318edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X with boolean bag of words\n",
    "X_bool_train = cv.fit_transform(preprocessed_train_data).toarray()\n",
    "X_bool_test = cv.fit_transform(preprocessed_test_data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5cc481ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X with TF bag of words\n",
    "X_tf_train = cv_tf.fit_transform(preprocessed_train_data).toarray()\n",
    "X_tf_test = cv_tf.fit_transform(preprocessed_test_data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f293acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X with TF-IDF bag of words\n",
    "X_tf_idf_train = cv_tfidf.fit_transform(preprocessed_train_data).toarray()\n",
    "X_tf_idf_test = cv_tfidf.fit_transform(preprocessed_test_data).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647a1b1c",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "Variasi algoritma yang dipilih untuk eksperimen adalah : \n",
    "1. Naive Bayes\n",
    "2. Logistic Regression\n",
    "3. Support Vector Machine\n",
    "4. k-Nearest Neighbors dengan n_neighbors = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "862d3875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran train data: (11000, 2)\n",
      "Ukuran test data: (500, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ukuran train data:\", train_data.shape)\n",
    "print(f\"Ukuran test data:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a380336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "def metrics(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"Model:\", classifier, \"\\n\")\n",
    "    print(f\"Accuracy Score  : {accuracy:.2}\")\n",
    "    print(f\"Precision Score : {precision:.2}\")\n",
    "    print(f\"Recall Score    : {recall:.2}\")\n",
    "    print(f\"F1 Score        : {f1:.2}\")\n",
    "    print()\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2626e47",
   "metadata": {},
   "source": [
    "### Bag of Words Variation with Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "268d392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_bool_train\n",
    "X_test = X_bool_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5625ac2c",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0c1b1a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MultinomialNB() \n",
      "\n",
      "Accuracy Score  : 0.44\n",
      "Precision Score : 0.36\n",
      "Recall Score    : 0.36\n",
      "F1 Score        : 0.33\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.46      0.31      0.37       204\n",
      "     neutral       0.18      0.05      0.07        88\n",
      "    positive       0.44      0.72      0.55       208\n",
      "\n",
      "    accuracy                           0.44       500\n",
      "   macro avg       0.36      0.36      0.33       500\n",
      "weighted avg       0.40      0.44      0.39       500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 64  11 129]\n",
      " [ 24   4  60]\n",
      " [ 51   7 150]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4b6826",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e1e912ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression() \n",
      "\n",
      "Accuracy Score  : 0.38\n",
      "Precision Score : 0.35\n",
      "Recall Score    : 0.33\n",
      "F1 Score        : 0.33\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.36      0.41      0.38       204\n",
      "     neutral       0.29      0.12      0.17        88\n",
      "    positive       0.40      0.45      0.43       208\n",
      "\n",
      "    accuracy                           0.38       500\n",
      "   macro avg       0.35      0.33      0.33       500\n",
      "weighted avg       0.37      0.38      0.36       500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 83  16 105]\n",
      " [ 42  11  35]\n",
      " [103  11  94]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d903a346",
   "metadata": {},
   "source": [
    "#### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0ea5b1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearSVC() \n",
      "\n",
      "Accuracy Score  : 0.38\n",
      "Precision Score : 0.36\n",
      "Recall Score    : 0.33\n",
      "F1 Score        : 0.33\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.37      0.38      0.37       204\n",
      "     neutral       0.32      0.14      0.19        88\n",
      "    positive       0.40      0.49      0.44       208\n",
      "\n",
      "    accuracy                           0.38       500\n",
      "   macro avg       0.36      0.33      0.33       500\n",
      "weighted avg       0.37      0.38      0.37       500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 77  14 113]\n",
      " [ 36  12  40]\n",
      " [ 96  11 101]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "classifier = LinearSVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38538529",
   "metadata": {},
   "source": [
    "#### k-Nearest Neighbors (k-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a1a30773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: KNeighborsClassifier() \n",
      "\n",
      "Accuracy Score  : 0.35\n",
      "Precision Score : 0.32\n",
      "Recall Score    : 0.32\n",
      "F1 Score        : 0.31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.54      0.46       204\n",
      "     neutral       0.19      0.22      0.20        88\n",
      "    positive       0.37      0.21      0.26       208\n",
      "\n",
      "    accuracy                           0.35       500\n",
      "   macro avg       0.32      0.32      0.31       500\n",
      "weighted avg       0.35      0.35      0.33       500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[111  43  50]\n",
      " [ 45  19  24]\n",
      " [125  40  43]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da6295",
   "metadata": {},
   "source": [
    "### Bag of Words Variation with Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "261e507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_tf_train\n",
    "X_test = X_tf_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606bd353",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de294646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MultinomialNB() \n",
      "\n",
      "Accuracy Score  : 0.39\n",
      "Precision Score : 0.37\n",
      "Recall Score    : 0.37\n",
      "F1 Score        : 0.37\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.41      0.48      0.44       204\n",
      "     neutral       0.26      0.27      0.26        88\n",
      "    positive       0.44      0.36      0.40       208\n",
      "\n",
      "    accuracy                           0.39       500\n",
      "   macro avg       0.37      0.37      0.37       500\n",
      "weighted avg       0.40      0.39      0.39       500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 98  42  64]\n",
      " [ 34  24  30]\n",
      " [105  28  75]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd775fb",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab8dcb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression() \n",
      "\n",
      "Accuracy Score  : 0.39\n",
      "Precision Score : 0.36\n",
      "Recall Score    : 0.35\n",
      "F1 Score        : 0.35\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.41      0.57      0.48       204\n",
      "     neutral       0.29      0.18      0.22        88\n",
      "    positive       0.39      0.31      0.34       208\n",
      "\n",
      "    accuracy                           0.39       500\n",
      "   macro avg       0.36      0.35      0.35       500\n",
      "weighted avg       0.38      0.39      0.38       500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[116  17  71]\n",
      " [ 43  16  29]\n",
      " [122  22  64]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539d4682",
   "metadata": {},
   "source": [
    "#### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3032681e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearSVC() \n",
      "\n",
      "Accuracy Score  : 0.4\n",
      "Precision Score : 0.39\n",
      "Recall Score    : 0.36\n",
      "F1 Score        : 0.36\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.41      0.58      0.48       204\n",
      "     neutral       0.36      0.18      0.24        88\n",
      "    positive       0.40      0.32      0.35       208\n",
      "\n",
      "    accuracy                           0.40       500\n",
      "   macro avg       0.39      0.36      0.36       500\n",
      "weighted avg       0.40      0.40      0.39       500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[119  14  71]\n",
      " [ 44  16  28]\n",
      " [127  15  66]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "classifier = LinearSVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e4a3c4",
   "metadata": {},
   "source": [
    "#### k-Nearest Neighbors (k-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b10cd4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: KNeighborsClassifier() \n",
      "\n",
      "Accuracy Score  : 0.33\n",
      "Precision Score : 0.33\n",
      "Recall Score    : 0.34\n",
      "F1 Score        : 0.27\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.60      0.48       204\n",
      "     neutral       0.19      0.35      0.24        88\n",
      "    positive       0.39      0.05      0.09       208\n",
      "\n",
      "    accuracy                           0.33       500\n",
      "   macro avg       0.33      0.34      0.27       500\n",
      "weighted avg       0.36      0.33      0.28       500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[123  70  11]\n",
      " [ 51  31   6]\n",
      " [132  65  11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d141a6",
   "metadata": {},
   "source": [
    "### Bag of Words Variation with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "58883270",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_tf_idf_train\n",
    "X_test = X_tf_idf_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed384de",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "18e1036a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MultinomialNB() \n",
      "\n",
      "Accuracy Score  : 0.44\n",
      "Precision Score : 0.36\n",
      "Recall Score    : 0.36\n",
      "F1 Score        : 0.33\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.46      0.31      0.37       204\n",
      "     neutral       0.18      0.05      0.07        88\n",
      "    positive       0.44      0.72      0.55       208\n",
      "\n",
      "    accuracy                           0.44       500\n",
      "   macro avg       0.36      0.36      0.33       500\n",
      "weighted avg       0.40      0.44      0.39       500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 64  11 129]\n",
      " [ 24   4  60]\n",
      " [ 51   7 150]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82460535",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4ca77c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression() \n",
      "\n",
      "Accuracy Score  : 0.38\n",
      "Precision Score : 0.35\n",
      "Recall Score    : 0.33\n",
      "F1 Score        : 0.33\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.36      0.41      0.38       204\n",
      "     neutral       0.29      0.12      0.17        88\n",
      "    positive       0.40      0.45      0.43       208\n",
      "\n",
      "    accuracy                           0.38       500\n",
      "   macro avg       0.35      0.33      0.33       500\n",
      "weighted avg       0.37      0.38      0.36       500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 83  16 105]\n",
      " [ 42  11  35]\n",
      " [103  11  94]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b915c7cd",
   "metadata": {},
   "source": [
    "#### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f5a335e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearSVC() \n",
      "\n",
      "Accuracy Score  : 0.38\n",
      "Precision Score : 0.36\n",
      "Recall Score    : 0.33\n",
      "F1 Score        : 0.33\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.37      0.38      0.37       204\n",
      "     neutral       0.32      0.14      0.19        88\n",
      "    positive       0.40      0.49      0.44       208\n",
      "\n",
      "    accuracy                           0.38       500\n",
      "   macro avg       0.36      0.33      0.33       500\n",
      "weighted avg       0.37      0.38      0.37       500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 77  14 113]\n",
      " [ 36  12  40]\n",
      " [ 96  11 101]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "classifier = LinearSVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26234378",
   "metadata": {},
   "source": [
    "#### k-Nearest Neighbors (k-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3fc83c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: KNeighborsClassifier() \n",
      "\n",
      "Accuracy Score  : 0.35\n",
      "Precision Score : 0.32\n",
      "Recall Score    : 0.32\n",
      "F1 Score        : 0.31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.54      0.46       204\n",
      "     neutral       0.19      0.22      0.20        88\n",
      "    positive       0.37      0.21      0.26       208\n",
      "\n",
      "    accuracy                           0.35       500\n",
      "   macro avg       0.32      0.32      0.31       500\n",
      "weighted avg       0.35      0.35      0.33       500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[111  43  50]\n",
      " [ 45  19  24]\n",
      " [125  40  43]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "metrics(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
